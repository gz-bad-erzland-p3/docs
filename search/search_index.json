{"config":{"lang":["de"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Einleitung","text":""},{"location":"#vorwort","title":"Vorwort","text":"<p>In dieser Dokumentation sind alle Arbeitsschritte des Projektes protokolliert. Ebenso sind hier alle wichtigen Dokumente abgelegt, die w\u00e4hrend des Projektes erstellt wurden.</p>"},{"location":"#projektteilnehmer","title":"Projektteilnehmer","text":""},{"location":"#anwendungsentwicklung","title":"Anwendungsentwicklung","text":"<ul> <li><p>Anton Hofmann [Projektleiter]</p></li> <li>Richard Peters [Bereichsleiter]</li> <li>Tommy Franke</li> <li>Alex Hartrumpf</li> </ul>"},{"location":"#systemintegration","title":"Systemintegration","text":"<ul> <li>Luca-Leon Sefrin [Bereichsleiter]</li> <li>Max Stephan</li> </ul>"},{"location":"#allgemeine-informationen","title":"Allgemeine Informationen","text":"<p>Zur Vereinfachung der Stundenerfassung entspricht eine Stunde im Dokument einer Schulstunde (45 min).</p>"},{"location":"projektdefinition/","title":"1. Projektdefinition","text":""},{"location":"projektdefinition/#11-protokoll-kundengesprach","title":"1.1 Protokoll Kundengespr\u00e4ch","text":"<p>Unser Team hat nach Analyse des Projektauftrages ein Gespr\u00e4ch mit dem zust\u00e4ndigen Gemeindemitarbeiter Herr Gutfried gehalten. Dort wurden offene Fragen gekl\u00e4rt und weitere Anforderungen festgelegt. </p>  Das Gespr\u00e4chsprotokoll kann unter folgendem Link abgerufen werden:  Protokoll_Kundengespra\u0308ch.pdf"},{"location":"projektdefinition/#12-lastenheft","title":"1.2 Lastenheft","text":"<p>Anhand des Projektauftrages und dem Protokoll des Kundengespr\u00e4chs war es nun m\u00f6glich ein Lasteheft zu erstellen. </p> Das Lastenheft kann unter folgendem Link abgerufen werden:  Lastenheft.pdf"},{"location":"projektdefinition/#13-pflichtenheft","title":"1.3 Pflichtenheft","text":"<p>Nach Unterschrift des Lastenhefts haben wir uns im Team zusammengesetzt und die Umsetzung des Projektes besprochen. Daraus entwickelten wir dann ein Pflichtenheft, welches das Konzept sowie die Anforderungsbeschreibung beinhaltet. Ebenso ist dort eine Kosten\u00fcbersicht und die Abnahmekriterien enthalten. </p> Das Pflichtenheft kann unter folgendem Link abgerufen werden:  Pflichtenheft.pdf"},{"location":"projektdurchfuehrung/","title":"3. Projektdurchf\u00fchrung","text":""},{"location":"projektdurchfuehrung/#31-anwendungsentwicklung","title":"3.1 Anwendungsentwicklung","text":""},{"location":"projektdurchfuehrung/#311-landingpage","title":"3.1.1 Landingpage","text":"<ul> <li>Frontend </li> </ul> <p>Zuerst wurde eine Landingpage erstellt, \u00fcber die man zum Online-Reservierungs-Tool gelangt. </p> <p></p>"},{"location":"projektdurchfuehrung/#312-arbeitsplatzkonfiguration","title":"3.1.2 Arbeitsplatzkonfiguration","text":"<ul> <li>Frontend </li> </ul> <p>Terminauswahl:   Als erstes gelangt man zur Terminauswahl. Dort k\u00f6nnen der Zeitraum und die Start-, bzw. Endzeit ausgew\u00e4hlt werden.</p> <p> </p> <p>In der Terminauswahl muss die Mindest- und Maximalmietdauer beachtet werden. Wird die Mietdauer \u00fcber-/unterschritten wird eine Meldung oben in der Ecke angezeigt. </p> <p> </p> <p>Arbeitsplatzauswahl: Bei der Arbeitsplatzauswahl kann zwischen Einzel- oder Doppelarbeitsplatz gew\u00e4hlt werden. Optionen, welche ausgegraut werden sind aufgrund anderer Buchungen nicht mehr ausw\u00e4hlbar. </p> <p> </p> <p>Konfiguration: In der Konfiguration muss als erstes ausgew\u00e4hlt werden, ob ein eigenes Ger\u00e4t mitgebracht werden soll oder nicht. Falls keins mitgebracht wird besteht die m\u00f6glichkeit verschiedene Ger\u00e4te zu konfigurieren. </p> <p> </p> <p>Wird \"Ich brauche ein Ger\u00e4t\" gew\u00e4hlt, erweitert sich die Seite und es werden weitere Konfigurationsm\u00f6glichkeiten angezeigt. Nun kann zwischen Laptop, Desktop-PC und Barebone entschieden werden, eine Auswahl \u00fcber das Betriebssystem getroffen und kostenlose Browser und Kommunikationsapplikationen ausgew\u00e4hlt werden. Zus\u00e4tzlich k\u00f6nnen noch Bemerkungen bzw. W\u00fcnsche eingetragen werden. </p> <p> </p> <ul> <li>Backend </li> </ul>"},{"location":"projektdurchfuehrung/#313-login","title":"3.1.3 Login","text":"<ul> <li>Frontend </li> </ul> <p>Login:  Der Login erfolgt \u00fcber die Eingabe von E-Mail und Passwort. </p> <p> </p> <p>Registrierung:  Wenn noch kein Konto vorhanden ist, besteht die M\u00f6glichkeit sich zu registrieren. </p> <ul> <li>Backend </li> </ul> <p>Zur Speicherung der Login-Daten in der Firebase-Datenbank werden diese mittels HTTP- bzw- REST-Request an die REST-API (Firebase) \u00fcbermittelt. Nach Abschluss der Registrierung wird eine Best\u00e4tigungsmail gesendet.</p> <p></p>"},{"location":"projektdurchfuehrung/#314-profilubersicht","title":"3.1.4 Profil\u00fcbersicht","text":"<ul> <li>Frontend </li> </ul> <p>In der Profil\u00fcbersicht werden die Daten des Kontos angezeigt. Hier ist es auch m\u00f6glich das Passwort zur\u00fcckzusetzen, die Adresse zu \u00e4ndern oder das Konto zu l\u00f6schen. </p> <p>Buchungs\u00fcbersicht </p> In der Profil\u00fcbersicht werden die Buchungen angezeigt und es besteht die M\u00f6glichkeit die Buchungen zu stonieren.  <ul> <li>Backend </li> </ul>"},{"location":"projektdurchfuehrung/#315-reservierung","title":"3.1.5 Reservierung","text":"<ul> <li>Frontend </li> </ul> <p>Nach erfolgreicher Anmeldung/Reservierung wird der Interessent gebeten auf einen Button zu klicken. Hiermit ist der konfigurierte Arbeitsplatz f\u00fcr 20min reserviert und es werden die Zahlungsmethoden angezeigt. </p> <p> </p> <ul> <li>Backend </li> </ul>"},{"location":"projektdurchfuehrung/#316-dokumentation-hilfe-seiten","title":"3.1.6 Dokumentation / Hilfe Seiten","text":"<ul> <li>F\u00fcr die Hilfe im Online-Reservierungs-Tool wird auf die Projektdokumentation verwiesen. </li> </ul>"},{"location":"projektdurchfuehrung/#317-zahlungsseite","title":"3.1.7 Zahlungsseite","text":"<ul> <li>Frontend </li> </ul> <p>Auf der Zahlungsseite kann zwischen 3 Zahlungsmethoden ausgew\u00e4hlt werden. </p> <p>Nach Auswahl der Zahlungsmethode wird die Meldung \"Buchung erfolgreich!\" angezeigt. Damit ist die Reservierung abgeschlossen und der Arbeitsplatz f\u00fcr den gew\u00fcnschten Zeitraum gebucht. </p> <ul> <li>Backend </li> </ul> <p>Best\u00e4tigungsmail bei Buchungsabschluss </p>"},{"location":"projektdurchfuehrung/#319-programmtests","title":"3.1.9 Programmtests","text":""},{"location":"projektdurchfuehrung/#3110-aufgetretene-problemehurden","title":"3.1.10 aufgetretene Probleme/H\u00fcrden","text":"<ul> <li> <p>Landingpage</p> </li> <li> <p>Terminauswahl</p> </li> <li> <p>Arbeitsplatztypauswahl</p> </li> <li> <p>Arbeitsplatzkonfiguration</p> </li> <li> <p>Login</p> </li> <li> <p>Profil\u00fcbersicht</p> </li> <li> <p>Zahlungs\u00fcbersicht</p> </li> <li> <p>Backend</p> </li> </ul>"},{"location":"projektdurchfuehrung/#32-systemintegration","title":"3.2 Systemintegration","text":""},{"location":"projektdurchfuehrung/#321-erstellung-der-netzwerkubersich","title":"3.2.1 Erstellung der Netzwerk\u00fcbersich","text":"Netzadresse Subnetzmaske Gateway DHCP Verwendung Rotes Netzwerk 192.168.72.0 (Class C) 255.255.255.0 (/24) 192.168.72.2 Nein Zugang zum Internet Orangenes Netzwerk 192.168.1.0 (Class C) 255.255.255.0 (/24) 192.168.1.2 Nein Demilitarisierte Zone (DMZ) Gr\u00fcnes Netzwerk 172.15.0.0 (Class B) 255.255.0.0 (/16) 172.15.0.2 Ja Netz f\u00fcr interne/administrierte Ger\u00e4te Blaues Netzwerk 172.16.0.0 (Class B) 255.255.0.0 (/16) 172.16.0.2 Ja Netz f\u00fcr externe/nicht administrierte Ger\u00e4te <p>Die Netze werden durch den integrierten DHCP des VMWare Players bereitgestellt. Die Konfiguration dieses DHCPs erfolgt \u00fcber die \"vmnetconfig\"-Datei (siehe ./doku/vmnetconf/vmnetconfig)</p> <p>\u00dcbersicht der Server</p> Name Netz Verwendung lnx-ipfire (siehe 2) Rot Firewall, DHCP, DNS-forwarder lnx-dns (siehe 3) Gr\u00fcn Interner DNS-Server lnx-docker (siehe 4) Orange Docker Host (Webserver, CA) lnx-cmk (siehe 5) Gr\u00fcn Monitoring des Webservers lnx-ansible-ctl (siehe) Gr\u00fcn Ansible Controle Node <p>Zugangsdaten</p> Server Benutzer Passwort lnx-ipfire root bgyb admin bgyb lnx-dns secnetit bgyb lnx-docker admin Test! lnx-checkMK root bgyb cmkadmin bgyb lnx-ansible-ctl root 01219dd. admin bgyb"},{"location":"projektdurchfuehrung/#322-automatisierung-des-webservers","title":"3.2.2 Automatisierung des Webservers","text":"<p>Die Bereitstellung und Konfiguration des Webservers erfolgt \u00fcber Vagrant und Ansible.</p>"},{"location":"projektdurchfuehrung/#3221-bereitstellung-durch-vagrant","title":"3.2.2.1 Bereitstellung durch Vagrant","text":"<p>Vagrant l\u00e4uft mit Version 2.3.4 auf dem lokalen Windows Rechner. F\u00fcr die Bereitstellung der VM wird im Verzeichnis das Vagrantfile ben\u00f6tigt. Die VM kann dann wie folgt gesatrtet werden: <pre><code>C:\\Vagrant\\lnx-docker&gt;vagrant up --no-provision\n</code></pre> Dabei wird der \".vagrant\"-Ordner im aktuellen Verzeichnis angelegt, in dem sich dann bspw. die VMDK-Dateien (virutelle Festplatte) der VM befinden.</p> <p>Bei der Provisioniert wird unter anderem folgendes definiert: - Name der Vagrantbox, auf der die VM gebaut wird generic/centos9s - allgemeine Festlegungen der Ressourcen (2 GB vRAM, 2 vCPUs, 128 GB Festplatte (thin provisioned)) - Netzwerkadapter mit MAC-Adresse und virtuellem Netzwerk Die restlichen Punkte k\u00f6nnen aus dem Vagrantfile selbst entnommen werden.</p>"},{"location":"projektdurchfuehrung/#3222-konfiguration-durch-ansible","title":"3.2.2.2 Konfiguration durch Ansible","text":"Version ansible core 2.13.3 Hardware CPU: 2 KerneRAM: 2GBHard Disk: 20GB IP-Adresse 172.15.254.252 <p>Die Konfiguration des Webservers erfolg durch den Ansible Control Node (lnx-ansible-ctl). </p> <p>Der Ordner lnx-docker von Windows ist direkt \u00fcber die VMware Workstation mit der VM geteilt und an /home/admin/vagrant gemountet.</p> <p>Au\u00dferdem sind folgende Inhalte zus\u00e4tzlich in das Arbeitsverzeichnis von Ansible gemappt: </p> <p>Die vorkonfigurierte \"ssh-config\"-Datei im lnx-docker-Ordner wird f\u00fcr die SSH-Verbindung zum Host verwendet. In dieser wird unter anderem der zu verwendende Port und die Schl\u00fcssel f\u00fcr die Verbindung definiert.</p>"},{"location":"projektdurchfuehrung/#32221-collection","title":"3.2.2.2.1 Collection","text":"<p>Die Collection-Liste kann mit  <pre><code>ansible-galaxy collection install name.connection\n</code></pre> erweitert werden. Der aktuelle Stand ist in dieser Liste einsehbar.</p>"},{"location":"projektdurchfuehrung/#32222-playbooks","title":"3.2.2.2.2 Playbooks","text":"<p>Im Ordner .playbooks im Arbeitsverzeichnis sind alle relevanten Dateien zu finden.</p> <p>Die Konfigurationsdatei \"ansible.cfg\" bilden dabei den Grundstock f\u00fcr die Nutzung von Ansible.</p> <p>Die \"hosts\"-Datei enth\u00e4lt die Managed Nodes, welche mittels dem Control Node konfiguriert werden. Diese k\u00f6nnen in Gruppen und die einzelnen Hosts aufgeteilt werden.</p> <p>Die \"resolve\"-Datei kann als interner DNS verstanden werden, der zus\u00e4tzlich zum DNS im Netzwerk lokal Adressen aufl\u00f6sen kann.</p> <p>Die \"site.yml\"-Datei ist das Playbook, in dem die Konfiguration des Webservers definiert ist. Das Playbook kann von dem Control Node aus, aus richtigen Ordner wie folgt ausgef\u00fchrt werden: <pre><code>[admin@lnx-ansible-ctl lnx-docker]$ ansible-playbook --vault-password-file=vault_pass playbooks/site.yml\n</code></pre> Die Datei, die das Passwort zum Vault enth\u00e4lt, muss seperat behandelt werden, damit die Sicherheit gew\u00e4hrleistet sein kann.</p> <p>In dem Hauptplaybook wird im Teil der \"pre_task\", nach einer Abfrage des aktuellen Nutzers, der Standardnutzer, der durch Vagrant mitgelieft wird, auf einen eigenen Nutzer ge\u00e4ndert. Im Hauptteil werden dann allgemeine Einstellungen gesetzt und andere Playbooks importiert.  In den \"post_tasks\" werden alle nicht benutzten Container und der mitgelieferte Standardnutzer von Vagrant entfernt.</p> <p>F\u00fcr genauere Informationen zu den verschiedenen Playbooks empfielt es sich, diese selbst zu analysieren.</p> <p>Im Ordner group_vars, im Hauptverzeichnis, befinden sich im Ordner \"all\" die yaml-Dateien \"centOS.yml\" und \"vault.yml\". In der centOS-Datei sind alle ben\u00f6tigten Variablen f\u00fcr das Playbook definiert. Die vault-Datei ist direkt \u00fcber das von Ansible mitgelieferte Tool \"Ansible Vault\" mit AES256 verschl\u00fcsselt. Diese Datei kann nur im Control Node auf der Kommandozeile bearbeitet werden. Eine genauere Anleitung kann hier gefunden werden.</p> <p>Der Ordner \"files\" bietet einen zentralen Ort, an dem alle Dateien zu finden sind, die w\u00e4hrend der Konfiguration des Managed Nodes auf diesen \u00fcbrtragen werden.</p> <p>Im Ordner \"units\" befinden sich weitere Playbooks, die, wie weiter oben beschrieben, im Hauptplaybook inkludiert werden.</p> <p>check-git-service.yml - Skript zur automatischen Aktualisierung der Webseite wird bereitgestellt - systemd.timer wird konfiguriert - mehr Informationen: siehe #324-automatische-aktualisierung-der-website</p> <p>firewalld.yml - Firewalld wird angepasst   - Ports und Services werden freigeschalten </p> <p>install-podman.yml - Podman wird installiert</p> <p>install-repository.yml - Repositorys werden installiert</p> <p>install-req-packages.yml - ben\u00f6tigte Pakete werden installiert</p> <p>remove-nextjs-systemd.yml - systemd container-nextjs-instance wird entfernt</p> <p>setup-cmk-agent.yml - CheckMK Agent wird vom Server heruntergeladen und anschlie\u00dfend installiert - Registrierung am Server erfolgt</p> <p>setup-nextjs.yml - Podman Container mit Webseite wird im Usercontext gestartet  - Image wird durch Dockerfile definiert - systemd-Service wird generiert </p> <p>setup-nextjs-service.yml - generierter Container Service wird aktiviert</p> <p>setup-nginx.yml - Podman Container mit Nginx wird im Usercontext gestartet - ben\u00f6tigte Zertifikatsdatei werden kopiert - systemd-Service wird generiert</p> <p>setup-nginx-service.yml - generierter Container Service wird aktiviert</p> <p>setup-pod.yml - der Pod \"service_pod\" wird entfernt und neu generiert - hier werden auch die ben\u00f6tigten Ports exposed</p> <p>setup-proxy.yml - mittels ICMP-Ping wird gepr\u00fcft, ob der Schulproxy erreichbar ist - sollte dieser Erreichbar sein, wird auf dem Control Node der Proxy eingerichtet</p> <p>setup-ssl-cert.yml - die Zertifikate f\u00fcr die Webseite wird \u00fcber einen Container erstellt - Podman Container zur Zertifikatserstellung wird mit allen ben\u00f6tigten Parametern f\u00fcr das Zertifikat ausgestellt</p> <p>setup-user.yml - Nutzer wird erstellt und in \"admin\"- und \"wheel\"-Gruppen aufgenommen - die Zertifikate zur Anmeldung \u00fcber SSH werden verschoben</p> <p>Die hier dargestellte Reihenfolge der Playbooks ist so nicht im Hauptplaybook inkludiert. Die tats\u00e4chliche Reihenfolge ist aus dem Playbook \"site.yml\" zu entnehmen.</p> <p>Sowohl der Nginx-, als auch der Nextjs-Container laufen im \"service_pod\"-Pod. Durch diesen werden die Ports 3000 und 8443 exposed. Der Port 8443 wird vom Nginx-Container verwendet, um die Webseite nach au\u00dfen \u00fcber einen verschl\u00fcsselten TSL-Verbindung bereitzustellen. Der Port 3000 wird vom verwendet, damit der Nginx-Container mit dem Nextjs-Container kommunizieren kann. Diese Kommunikation l\u00e4uft unverschl\u00fcsselt innerhalb des Pods. Der Nginx-Container dient dabei als Upstream Server.</p>"},{"location":"projektdurchfuehrung/#323-monitoring","title":"3.2.3 Monitoring","text":""},{"location":"projektdurchfuehrung/#3231-systemuberblick","title":"3.2.3.1 System\u00fcberblick","text":"Version Open Monitoring Distribution Version 2.1.0p20.cre Hardware CPU: 2 KerneRAM: 2GBHard Disk: 20GB IP-Adresse 172.15.0.10"},{"location":"projektdurchfuehrung/#3232-installation","title":"3.2.3.2 Installation","text":"<p>Die Installation erfolge anhand der von CheckMK zur Verf\u00fcgung gestellten Anleitung.</p>"},{"location":"projektdurchfuehrung/#3233-konfiguration","title":"3.2.3.3 Konfiguration","text":"<ul> <li>Erstellung der Site \"gzbe\"</li> <li>interne Firewall angepasst: <pre><code>[root@lnx-cmk ~]# firewall-cmd --list-all\npublic (active)\n  target: default\n  icmp-block-inversion: no\n  interfaces: ens160\n  sources:\n  services: cockpit dhcpv6-client http https ssh\n  ports: 80/tcp 443/tcp 8000/tcp\n  protocols:\n  forward: yes\n  masquerade: no\n  forward-ports:\n  source-ports:\n  icmp-blocks:\n  rich rules:\n</code></pre></li> <li>internen Webserver den Zugriff auf Interface ens160 via SE-Linux erlauben <pre><code>setsebool -P httpd_can_network_connect 1\n</code></pre></li> <li>Service \"httpd\" starten und aktivieren</li> <li>Anpassung der IPFire-Firewall (siehe Firewall-Regeln)</li> </ul>"},{"location":"projektdurchfuehrung/#3234-agentinstallation","title":"3.2.3.4 Agentinstallation","text":"<p>Die \u00dcberwachung von Servern l\u00e4uft \u00fcber einen mitgelieferten Agent, welcher auch auf dem CheckMK-Server selbst installiert wurde. Es gibt zwei M\u00f6glichkeiten, den Agent zu finden:</p> <ul> <li>lokal: /opt/omd/versions/2.1.0p20.cre/share/check_mk/agents/</li> <li>\u00fcber die Webansicht: http://172.15.254.253/gzbe/check_mk/agents/ </li> </ul> <p>Eine konkrete Anleitung f\u00fcr die Agentinstallation und Registrierung wird auch von CheckMK zur Verf\u00fcgung gestellt.</p> <p>Die ben\u00f6tigten Ports zur Kommunikation sind in der Firewall in der \"check_mk-agent-group\"-Gruppe konfiguriert.</p>"},{"location":"projektdurchfuehrung/#324-automatische-aktualisierung-der-website","title":"3.2.4 Automatische Aktualisierung der Website","text":"<p>Die Aktualisierung der Webseite erfolg \u00fcber ein Skript, welches durch einen Service ausgef\u00fchrt wird. Dieser Service wird durch einen Timer verwaltet.</p> <p>Die Funktionsweise ist wie folgt: - jeden Tag 0 Uhr werden die CommitIDs der Onlineversion und der lokalen Version verglichen  - sind diese ungleich wird die Version von Github heruntergeladen und damit ein Textimage gebaut - wenn der Container fehlerfrei gebaut werden konnte, wird er wieder entfernt - anschlie\u00dfend wird die aktuelle Webseite \u00fcber den Dienst gestoppt - die Images werden umgetagget bzw. entfernt - der neue Container wird mit seinem Dienst neu erstellt</p>"},{"location":"projektdurchfuehrung/#325-firewall","title":"3.2.5 Firewall","text":""},{"location":"projektdurchfuehrung/#3251-systemuberblick","title":"3.2.5.1 System\u00fcberblick","text":"Version IP-Fire Ver. 2.27 x86_64 - Core 172 Hardware CPU: 2 KerneRAM: 2GBHard Disk: 20GB IP-Adresse(n) Rotes Interface: 192.168.72.254/24Orangenes Interface: 192.168.1.2/24Gr\u00fcnes Interface: 172.15.0.2/16Blaues Interface: 172.16.0.2/16"},{"location":"projektdurchfuehrung/#3251-konfiguration","title":"3.2.5.1 Konfiguration","text":""},{"location":"projektdurchfuehrung/#32511-allgemein","title":"3.2.5.1.1 Allgemein","text":"<ul> <li>Installation der virtuell Maschine durch das bereitgestellte Image von IPFire</li> <li>Einrichtung der Benuzter \"admin\" und \"root\" </li> <li>Zuweisung der Netzwerkadapter und deren IP-Adressen (siehe Netzwerk\u00fcbersicht)</li> <li>weitere Konfiguration \u00fcber Web-User-Interface (WUI), zu erreichen \u00fcber gr\u00fcnen Netzwerkadapter und Port 444 (https://172.15.0.2:444)</li> <li>SSH-Zugriff \u00fcber \"System\" \u2192 \"SSH Access\" aktivieren </li> </ul>"},{"location":"projektdurchfuehrung/#32511-dhcp","title":"3.2.5.1.1 DHCP","text":"<p>In den blauen und gr\u00fcnen Netzwerksegmenten ist die Firewall gleichzeitig der DHCP-Server. - Anpassung unter \"Network\" \u2192 \"DHCP Server\" wie folgt:</p> Gr\u00fcnes Interface Blaues Interface Enabled yes yes Netzwerk 172.15.0.0/16 172.16.0.0/16 Start-/End-Address 172.15.1.0 / 172.15.254.254 172.16.1.0 / 172.16.254.254 Min/Max Lease Time 60min / 120min 60min / 120min DNS-Server 172.15.254.254172.15.0.2 172.15.254.254172.16.0.2 <p>In beiden Netzen bleibt die Null im dritten Oktett f\u00fcr statische IP-Adressen frei.  Daher stehen sowohl die 172.15.0.1 bis 172.15.0.254 im gr\u00fcnen Netz und 172.16.0.1 bis 172.16.0.254 im blauen Netz f\u00fcr statische Adressen zur Verf\u00fcgung.</p> <p>Als prim\u00e4rer DNS-server ist der lnx-dns (siehe Einrichtung DNS-Server) in beiden Netzen eingetragen. Als sekund\u00e4rer DNS-Server ist die Firewall selbst eingetragen (siehe DNS).</p> <p>Die folgende Tabelle zeigt die aktuell reservierten Adressen:</p> Name IP-Adresse DNS-Server (lnx-dns) 172.15.254.254 CheckMK-Server (lnx-cmk) 172.15.254.253 Control Node (lnx-ansible-ctl) 172.15.254.252"},{"location":"projektdurchfuehrung/#32512-dns","title":"3.2.5.1.2 DNS","text":"<ul> <li>als interner DNS-Server wird Unbound verwendet</li> <li>Konfiguration erfolgt \u00fcber WUI oder Konfigurationsdatei</li> <li>Firewall dient in aktueller Situation als DNS-Weiterleitung (leitet Anfragen an Kserver weiter)</li> <li>Schema der DNS-Anfragen:</li> </ul>"},{"location":"projektdurchfuehrung/#325121-konfiguration-uber-wui","title":"3.2.5.1.2.1 Konfiguration \u00fcber WUI","text":"<ul> <li>Konfiguration \u00fcber \"Network\" \u2192 \" \"Domain Name System\"</li> <li>aktuell ist der Kserver \u00fcber unbound.conf eingerichtet \u2192 wird nicht in WUI angezeigt</li> </ul>"},{"location":"projektdurchfuehrung/#325122-konfiguration-uber-unboundconf","title":"3.2.5.1.2.2 Konfiguration \u00fcber unbound.conf","text":"<ul> <li>Kserver unterst\u00fctzt kein DNSSEC \u2192 muss deaktiviert werden</li> <li>unbound.conf zu finden unter \"/etc/unbound/unbound.conf\"</li> <li> <p>\"harden-dnssec-stripped\" besonders zu beachten! <pre><code>        # Hardening Options\n        harden-large-queries: yes\n        harden-referral-path: yes\n        #harden-dnssec-stripped: yes\n</code></pre></p> </li> <li> <p>DNS-Weiterleitung \u00fcber die Option \"forward-zone\" wie folgt konfigurieren: <pre><code>forward-zone:\n                name: \".\"\n                forward-addr: 10.1.1.2 #add kserver as dns resolver\n</code></pre></p> </li> </ul>"},{"location":"projektdurchfuehrung/#32512-proxy","title":"3.2.5.1.2 Proxy","text":"<ul> <li>aktuell konfigurierter Proxy nur in Schulumgebung relevant</li> <li>Anpassungen unter \"Network\" \u2192 \"Web Proxy\" zu finden </li> <li>Schulproxy (10.254.5.100:3128) als Upstream Proxy Server einrichten </li> </ul>"},{"location":"projektdurchfuehrung/#32513-firewall-regeln","title":"3.2.5.1.3 Firewall-Regeln","text":""},{"location":"projektdurchfuehrung/#325131-firewall-gruppen","title":"3.2.5.1.3.1 Firewall-Gruppen","text":"<ul> <li>Konfiguration unter \"Firewall\" \u2192 \"Firewall Groups\"</li> <li>M\u00f6glichkeit, Protokolle oder Clients zu Gruppen zusammenfassen</li> <li>folgende Servicegruppe gibt es aktuell: </li> </ul> <p>check_mk-agent-group | Name                    | Port | Protocol | |-------------------------|------|----------| | check_mk-agent          | 6556 | TCP      | | check_mk-agent-register | 8000 | TCP      |</p> <p>dns | Name      | Port | Protocol | |-----------|------|----------| | DNS (TCP) | 53   | TCP      | | DNS (UDP) | 53   | UDP      |</p>"},{"location":"projektdurchfuehrung/#325131-firewall-regeln","title":"3.2.5.1.3.1 Firewall-Regeln","text":"<ul> <li>Konfiguration unter \"Firewall\" \u2192 \"Firewall Rules\"</li> </ul> Protocol Source Log Destination Handling Description ICMP Any [ ] Any accept ping global dns BLUE [X] 172.15.254.254 accept blue pinhole for DNS #internal# dns ORANGE [X] RED accept orange dns access #outgoing# dns 192.168.1.10 [X] 172.15.254.254 accept allow internal dns for lnx-docker ssh 172.15.254.254 [X] 192.168.1.10 accept ssh access from lnx-ansible-ctlto lnx-docker snmp GREEN [ ] Any accept snmp access to firewall https 192.168.1.10 [ ] Any accept internal https access check_mk-agent-group 192.168.1.10 [X] 172.15.254.254 accept access for cmk-agent from webserver"},{"location":"projektdurchfuehrung/#32513-zugang-blaues-netzwerk","title":"3.2.5.1.3 Zugang Blaues Netzwerk","text":"<ul> <li>Konfiguration unter \"Firewall\" \u2192 \"Blue Access\"</li> <li>blaues Netzwerk f\u00fcr nicht adminsitrierte Ger\u00e4te \u2192 Zugriff auf andere Netze &amp; WUI muss eingeschr\u00e4nkt werden</li> <li>Kommunikation zwischen blauem und anderen Netzen grunds\u00e4tzlich blockiert </li> <li>rotes Netz von dieser Blockierung ausgeschlossen, wegen Internetzugang</li> </ul>"},{"location":"projektdurchfuehrung/#325131-mac-address-filtering","title":"3.2.5.1.3.1 MAC-Address filtering","text":"<ul> <li>standardm\u00e4\u00dfig wird MAC-Address filtering (MAf) durch IPFire aktiviert</li> <li>blockiert Internetzugang von Clients im blauen Netzwerk</li> <li>Netzadresse des blauen Netzes als Ger\u00e4t hinzuf\u00fcgen </li> </ul>"},{"location":"projektdurchfuehrung/#325132-wui-zugriff","title":"3.2.5.1.3.2 WUI Zugriff","text":"<ul> <li>Zugriff vom blauen Netz auf WUI der Firewall standardm\u00e4\u00dfig freigeschalten</li> <li>Anpassung der lokalen Firewall unter \"/etc/sysconfig/firewall.local\"</li> <li>Zugriff kann wie folgt \u00fcber blaues und gr\u00fcnes Netzwerk deaktiviert werden, wenn die Quelladresse aus dem blauen Netz kommt</li> </ul>"},{"location":"projektdurchfuehrung/#326-einrichtung-des-dns-servers","title":"3.2.6 Einrichtung des DNS Servers","text":""},{"location":"projektdurchfuehrung/#3261-systemuberblick","title":"3.2.6.1 System\u00fcberblick","text":"Version Dnsmasq Ver. 2.85 Hardware CPU: 1 KernRAM: 1GBHard Disk: 20GB IP-Adresse 172.15.254.254/16"},{"location":"projektdurchfuehrung/#3262-konfiguration","title":"3.2.6.2 Konfiguration","text":""},{"location":"projektdurchfuehrung/#32621-dnsmasq","title":"3.2.6.2.1 Dnsmasq","text":"<ul> <li>Konfiguration \u00fcber \"/etc/dnsmasq.conf\"</li> <li>aktueller Stand wie folg:</li> </ul> Zeile Syntax Nutzen 55-58 no-resolv Verhindert, dass dnsmasq aus der resolv.conf Datei liest 64-67 Server=172.15.0.2 Hinzuf\u00fcgen des DNS-Servers f\u00fcr die Aufl\u00f6sung von unbekannten Adressen 112-115 listen-address=127.0.0.1listen-address=172.15.254.254 Gibt die Interfaces vor, an denen nach DNS-Anfragen gelauscht werden soll"},{"location":"projektdurchfuehrung/#32622-dns-eintrage","title":"3.2.6.2.2 DNS-Eintr\u00e4ge","text":"<ul> <li>Konfiguration \u00fcber \"/etc/hosts\"</li> <li>aktueller Stand wie folgt:</li> </ul>"},{"location":"projektdurchfuehrung/#33-projektprasentation","title":"3.3 Projektpr\u00e4sentation","text":""},{"location":"projektdurchfuehrung/#331-vorbereitung","title":"3.3.1 Vorbereitung","text":""},{"location":"projektdurchfuehrung/#332-prasentation-kundenubergabe","title":"3.3.2 Pr\u00e4sentation / Kunden\u00fcbergabe","text":""},{"location":"projektentwurf/","title":"2. Projektentwurf","text":""},{"location":"projektentwurf/#21-feinkonzept","title":"2.1 Feinkonzept","text":"<p>Im Feinkonzept wurden anhand der Anforderungen des Pflichtenhefts User Stories erstellt und in einzelne Punkte untergliedert. Danach wurde eine zeitliche Planung in Form eines Ganttplan erstellt. F\u00fcr eine genaue Aufschl\u00fcsselung der anstehenden Kosten wurde eine detaillierte Kostenkalulation durchgef\u00fchrt. Neben der Planung der Ressourcen wurde zur Veranschaulichung des informationstechnischen Netzwerkes ein Netzwerkplan erstellt  (Der Netzwerkplan ist in 3. Projektdurchf\u00fchrung unter 3.2.6 Erstellung des Netzwerkplans zu finden). Weiter wurden Ma\u00dfnahmen zum Datenschutz und zur Datensicherheit spezifiziert.</p> Das Feinkonzept kann unter folgendem Link abgerufen werden:  Feinkonzept_v_1.3.pdf"},{"location":"projektentwurf/#22-ganttplan","title":"2.2 Ganttplan","text":""}]}